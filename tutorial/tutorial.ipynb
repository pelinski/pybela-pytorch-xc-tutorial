{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pybela tutorial\n",
    "In this workshop we'll be using jupyter notebooks and python to:\n",
    "1. Record a dataset of potentiometer sensor values\n",
    "2. Train a TCN to predict those values\n",
    "3. Cross-compile and deploy the model to run in real-time in Bela\n",
    "\n",
    "Connect your Bela to the laptop and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ssh-keyscan $BBB_HOSTNAME >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also import all the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pybela import Logger\n",
    "import asyncio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 – pybela basics\n",
    "\n",
    "[pybela](https://github.com/BelaPlatform/pybela/) allows sending data back and forth between python and Bela.\n",
    "\n",
    "For pybela to be able to communicate with Bela, there has to be a project running on the Bela. \n",
    "\n",
    "We have an example project in `/root/bela-code/pybela-basic`. Let's take a look at the cpp code.\n",
    "\n",
    "### c++ code\n",
    "The cpp code in `pybela-basics/render.cpp` reads the value of a potentiometer which controls the volume of a wave sound. The potentiometer value is stored in a `pot` variable which is defined in a special way so we can access it from python.\n",
    "\n",
    "You should connect a potentiometer to the Bela's analog input 0:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"_fritzing/potentiometer.png\" alt=\"potentiometer\" width=\"400\"/>\n",
    "</p>\n",
    "Let's take a look at the Watcher API in `pybela-basics/render.cpp`:\n",
    "\n",
    "\n",
    "The Watcher API in the Bela code allows \"watching\" variables in the Bela code so we can retrieve their values from python. First, we define the variables we want to watch this way:\n",
    "\n",
    "```cpp\n",
    "Watcher<float> pot(\"pot\"); // the \"pot\" variable is \"watched\"\n",
    "```\n",
    "\n",
    "In the `setup()` function, we initialize the Watcher:\n",
    "\n",
    "```cpp\n",
    "bool setup(BelaContext *context, void *userData) {\n",
    "\n",
    "  Bela_getDefaultWatcherManager()->getGui().setup(context->projectName);\n",
    "  Bela_getDefaultWatcherManager()->setup(\n",
    "      context->audioSampleRate); // set sample rate in watcher\n",
    "\n",
    "      ...\n",
    "```\n",
    "\n",
    "We need to tell the Watcher the rate at which we want to observe the variables. For that, we \"tick\" the Watcher clock in the `render()` function. Note that we only tick it at the analog rate, since \"pot\" is an analog variable (typicially read once per two audio frames):\n",
    "\n",
    "```cpp\n",
    "\n",
    "void render(BelaContext *context, void *userData) {\n",
    "\n",
    "  for (unsigned int n = 0; n < context->audioFrames; n++) {\n",
    "\n",
    "    uint64_t analogFramesElapsed = int((context->audioFramesElapsed + n) / 2);\n",
    "    Bela_getDefaultWatcherManager()->tick(\n",
    "        analogFramesElapsed); // tick the watcher clock\n",
    "\n",
    "    if (gAudioFramesPerAnalogFrame && !(n % gAudioFramesPerAnalogFrame)) {\n",
    "      pot = analogRead(context, n / gAudioFramesPerAnalogFrame, 0);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's now crosscompile this code and run it on the Bela.\n",
    "\n",
    "### xcompiling the cpp code \n",
    "\n",
    "To cross-compile the code, we use `cmake` and a cross-compilation toolchain. A cross-compilation toolchain tells `cmake` that even though we are compiling the code on our laptop, the code is meant to run on the Bela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/pybela-basic && cmake -S . -B build -DPROJECT_NAME=pybela-basic -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/pybela-basic && cmake --build build -j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now built an executable for the Bela, which is located at `bela-code/pybela-basic/build/pybela-basic`. Let's copy it to the Bela, along with the project files so we can access them from the Bela IDE, and the `waves.wav` file which is used by the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/pybela-basic/build/pybela-basic root@$BBB_HOSTNAME:Bela/projects/pybela-basic/\n",
    "!rsync -rvL --timeout 10 bela-code/pybela-basic/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/pybela-basic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it, open a terminal and ssh into the Bela and run the program:\n",
    "\n",
    "```bash\n",
    "ssh root@bela.local\n",
    "cd Bela/projects/pybela-basic && ./pybela-basic\n",
    "```\n",
    "(running this on the Jupyter notebook would block the cell and we need to be able to run the next cells!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python code\n",
    "Now we are ready to interact with the Bela code from python. First we import `pybela` and create a `Logger` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=Logger(ip=os.environ[\"BBB_HOSTNAME\"])\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Logger is connected to Bela. The Logger class allows us recording datasets locally in Bela and transferring them automatically to the host computer. \n",
    "\n",
    "Connect your headphones to the Bela audio output and run the cell below while you rotate the potentiometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = logger.start_logging(\"pot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds, you can stop the logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transfer is done, you can retrieve the logged data by reading the binary file in which it was saved. That binary file stores the data as timestamped buffers, which we are not interested on as we just want a continuous array of potentiometer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot\"], timestamp_mode=logger.get_prop_of_var(\"pot\", \"timestamp_mode\"))\n",
    "data = [data for _buffer in raw[\"buffers\"] for data in _buffer[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_rate = logger.sample_rate/2\n",
    "\n",
    "plt.plot(np.arange(len(data)) / analog_sample_rate, data)\n",
    "plt.title('Pot Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 – potentiometers dataset capture\n",
    "\n",
    "We are now ready to record a dataset with two potentiometers. Connect the second potentiometer to your Bela:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"_fritzing/potentiometer_2.png\" alt=\"potentiometer\" width=\"300\"/>\n",
    "</p>\n",
    "\n",
    " We will be running the `dataset-capture` project. Now the first potentiometer controls the waveshape of an LFO and the second potentiometer, the volume of the sound.\n",
    "\n",
    "Let's start by cross-compiling the code and copying it to Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/dataset-capture && cmake -S . -B build -DPROJECT_NAME=dataset-capture -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/dataset-capture && cmake --build build -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/dataset-capture/build/dataset-capture root@$BBB_HOSTNAME:Bela/projects/dataset-capture/\n",
    "!rsync -rvL --timeout 10 bela-code/dataset-capture/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/dataset-capture/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the `dataset-capture` project on the Bela:\n",
    "\n",
    "```bash\n",
    "ssh root@bela.local\n",
    "cd Bela/projects/dataset-capture && ./dataset-capture\n",
    "```\n",
    "\n",
    "Feel free to play around with the potentiometer and the piezo sensor. You can also edit the code in the IDE and re-run the project.\n",
    "\n",
    "Once you're ready. You can record a dataset of potentiometer and piezo sensor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=Logger(ip=os.environ[\"BBB_HOSTNAME\"])\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can time the length of your dataset using `asyncio.sleep(time_in_seconds)`. Note we are not using `time.sleep()` because it would block the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = logger.start_logging(variables=[\"pot1\", \"pot2\"])\n",
    "await asyncio.sleep(90)\n",
    "logger.stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot1_raw_data = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot1\"], timestamp_mode=logger.get_prop_of_var(\"pot1\", \"timestamp_mode\"))\n",
    "pot2_raw_data = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot2\"], timestamp_mode=logger.get_prop_of_var(\"pot2\", \"timestamp_mode\"))\n",
    "\n",
    "pot1_data = [data for _buffer in pot1_raw_data[\"buffers\"] for data in _buffer[\"data\"]]\n",
    "pot2_data = [data for _buffer in pot2_raw_data[\"buffers\"] for data in _buffer[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_rate = logger.sample_rate/2\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.arange(len(pot1_data)) / analog_sample_rate, pot1_data)\n",
    "plt.title('Pot 1 Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Second subplot for pie_data\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.arange(len(pot2_data)) / analog_sample_rate, pot2_data)\n",
    "plt.title('Pot 2 Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - train model\n",
    "Now we are ready to train our model.\n",
    "We can generate a pytorch compatible dataset using the `SensorDataset` class. This class divides the data you recorded previously in sequences of 512 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "batch_size = 32\n",
    "target_windows = 1\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, pot1_data, pot2_data, seq_len, target_windows):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # make len divisible by seq_len\n",
    "        _len = min(len(pot1_data), len(pot2_data))\n",
    "        _len = _len - (_len % seq_len)\n",
    "        pot1_data, pot2_data = pot1_data[:_len], pot2_data[:_len]\n",
    "        \n",
    "        pot1_sequences = torch.FloatTensor([pot1_data[i:i+seq_len] for i in range(0, len(pot1_data), seq_len)])\n",
    "        pot2_sequences = torch.FloatTensor([pot2_data[i:i+seq_len] for i in range(0, len(pot2_data), seq_len)])\n",
    "\n",
    "        self.inputs = torch.stack((pot1_sequences[:-target_windows], pot2_sequences[:-target_windows]), dim=2).to(self.device)\n",
    "        outputs=[]\n",
    "        for idx in range(1, len(pot1_sequences)-target_windows+1):\n",
    "            tgt_seq = torch.stack((pot1_sequences[idx:target_windows+idx].flatten(), pot2_sequences[idx:target_windows+idx].flatten()), dim=1)\n",
    "            outputs.append(tgt_seq)\n",
    "        self.outputs = torch.stack(outputs).to(self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.inputs[i], self.outputs[i]\n",
    "    \n",
    "dataset = SensorDataset(pot1_data, pot2_data, seq_len, target_windows)\n",
    "dataset_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a TCN. We will use an Adam optimiser with a learning rate of 0.001 and use the mean square error as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"Layer that removes trailing values to ensure causality in the TCN.\"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"A single temporal block in a TCN, with dilated causal convolutions and residual connections.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    \"\"\"A Temporal Convolutional Network (TCN) made up of multiple temporal blocks.\"\"\"\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2, upsample_factor=3):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        self.upsample_factor = upsample_factor  # Upsample factor as a parameter\n",
    "        \n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers.append(TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                        padding=(kernel_size-1) * dilation_size, dropout=dropout))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Upsample layer to increase sequence length by the upsample factor\n",
    "        self.upsample_layer = nn.ConvTranspose1d(num_channels[-1], num_channels[-1], kernel_size=self.upsample_factor, stride=self.upsample_factor)\n",
    "        \n",
    "        # Output layer to map back to the input feature size\n",
    "        self.output_layer = nn.Conv1d(num_channels[-1], num_inputs, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch_size, sequence_len, feature_size]\n",
    "        x = x.transpose(1, 2)  # Change shape to [batch_size, feature_size, sequence_len]\n",
    "        y = self.network(x)\n",
    "        \n",
    "        # Upsample the sequence length by the upsample factor\n",
    "        y = self.upsample_layer(y)\n",
    "        \n",
    "        # Map back to the original feature size\n",
    "        y = self.output_layer(y)  \n",
    "        y = y.transpose(1, 2)  # Change shape back to [batch_size, sequence_len*upsample_factor, feature_size]\n",
    "        return y\n",
    "\n",
    "\n",
    "batch_size, sequence_len, feature_size = 32, 512, 2\n",
    "upsample_factor = target_windows  # Define the upsample factor\n",
    "model = TemporalConvNet(num_inputs=feature_size, num_channels=[16, 32, 16], kernel_size=3, dropout=0.2, upsample_factor=upsample_factor)\n",
    "\n",
    "# Create a random tensor of shape [batch_size, sequence_len, feature_size]\n",
    "x = torch.randn(batch_size, sequence_len, feature_size)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)  # Output shape should be [batch_size, sequence_len*upsample_factor, feature_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "epoch_losses = np.array([])\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(\">> Epoch: {} <<\".format(epoch))\n",
    "\n",
    "    # training loop\n",
    "    batch_losses = np.array([])\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(dataset_loader)):\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        data = data.to(device=device, non_blocking=True)\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        targets = targets.to(device=device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)  # lower memory footprint\n",
    "        out = model(data)\n",
    "        loss = torch.sqrt(criterion(out, targets))\n",
    "        batch_losses = np.append(batch_losses, loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_losses = np.append(epoch_losses, batch_losses.mean().round(4))\n",
    "\n",
    "    print(f'Loss: {epoch_losses[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the loss to see how the training went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_epochs = range(1, epochs + 1)\n",
    "\n",
    "plt.scatter(x_epochs, epoch_losses, marker='o')\n",
    "plt.plot(x_epochs, epoch_losses, linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(x_epochs)  # Ensure x-axis has integer values for each epoch\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the model trained correctly by visualising some of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random indexes for plotting\n",
    "num_examples = 4\n",
    "random_indexes = np.random.choice(len(dataset), size=num_examples, replace=False)\n",
    "\n",
    "# Calculate the number of rows for the subplots\n",
    "num_rows = num_examples\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(12, 3 * num_rows))\n",
    "\n",
    "# Loop through random indexes and plot predictions\n",
    "for idx, ax_row in zip(random_indexes, axes):\n",
    "    input, target = dataset.__getitem__(idx)\n",
    "    output = model(input.unsqueeze(0))\n",
    "    \n",
    "    # Plot for the first dimension in the first column\n",
    "    ax_row[0].plot(target[:, 0].detach().cpu(), label='Target')\n",
    "    ax_row[0].plot(output[0, :, 0].detach().cpu(), label='Predictions')\n",
    "    ax_row[0].set_xlabel('Time')\n",
    "    ax_row[0].set_ylabel('Value')\n",
    "    ax_row[0].legend()\n",
    "    ax_row[0].set_ylim(0, 3)\n",
    "    ax_row[0].set_title(f'Figure for Index {idx} - Pot 1')\n",
    "    \n",
    "    # Plot for the second dimension in the second column\n",
    "    ax_row[1].plot(target[:, 1].detach().cpu(), label='Target')\n",
    "    ax_row[1].plot(output[0, :, 1].detach().cpu(), label='Prediction')\n",
    "    ax_row[1].set_xlabel('Time')\n",
    "    ax_row[1].set_ylabel('Value')\n",
    "    ax_row[1].legend()\n",
    "    ax_row[1].set_title(f'Figure for Index {idx} - Pot 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're ready, save the model so that we can export it into Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device='cpu')\n",
    "model.eval()\n",
    "script = torch.jit.script(model)\n",
    "path = \"bela-code/inference/model.jit\"\n",
    "script.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.load(path) # check model is properly saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - deploy and run\n",
    "\n",
    "The cell below will cross-compile and deploy the project to Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/inference && cmake -S . -B build -DPROJECT_NAME=inference -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/inference && cmake --build build -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/inference/build/inference root@$BBB_HOSTNAME:Bela/projects/inference/\n",
    "!rsync -rvL --timeout 10 bela-code/inference/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/inference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once deployed, you can run it from the Bela terminal (which you can access from your regular terminal typing `ssh root@bela.local`) by typing:\n",
    "```bash\n",
    "cd Bela/projects/inference\n",
    "./pot-inference -m model.jit\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
